{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e30c31a",
   "metadata": {},
   "source": [
    "# Collecting country data\n",
    "\n",
    "Many of the tutorials in this class have so far focused on processing at the country level. \n",
    "\n",
    "However, to produce a global map we need to do two things:\n",
    "    \n",
    "1. Create a composite set of global shapefiles based on our chosen GID level for each country.\n",
    "2. Collect country-level data estimates and collate them into a single file.\n",
    "3. Merge data produced in 1 and 2, and then visualize. \n",
    "\n",
    "Examples will now be given for each of these steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a761e60",
   "metadata": {},
   "source": [
    "## Creating a composite set of global shapefiles\n",
    "\n",
    "We can load in our shapes country-by-country and then append them to a list as a geojson structure. \n",
    "\n",
    "Finally, we can convert them to a `geopandas.GeoDataFrame` using the `from_features()` function, and then export them to a .shp file.\n",
    "\n",
    "Let us begin by processing our regions, and then we can collect them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea13a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import geopandas\n",
    "from shapely.geometry import MultiPolygon\n",
    "\n",
    "##first we need to define small shapes function\n",
    "def remove_small_shapes(x):\n",
    "    \"\"\"\n",
    "    Remove small multipolygon shapes.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    x : polygon\n",
    "        Feature to simplify.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MultiPolygon : MultiPolygon\n",
    "        Shapely MultiPolygon geometry without tiny shapes.\n",
    "\n",
    "    \"\"\"\n",
    "    if x.geometry.type == 'Polygon':\n",
    "        return x.geometry\n",
    "\n",
    "    elif x.geometry.type == 'MultiPolygon':\n",
    "\n",
    "        area1 = 0.003\n",
    "        area2 = 50\n",
    "\n",
    "        if x.geometry.area < area1: \n",
    "            return x.geometry\n",
    "\n",
    "        if x['GID_0'] in ['CHL','IDN', 'RUS', 'GRL','CAN','USA']:\n",
    "            threshold = 0.01\n",
    "        elif x.geometry.area > area2:\n",
    "            threshold = 0.1\n",
    "        else:\n",
    "            threshold = 0.001\n",
    "\n",
    "        new_geom = []\n",
    "        for y in list(x['geometry'].geoms):\n",
    "            if y.area > threshold:\n",
    "                new_geom.append(y)\n",
    "\n",
    "        return MultiPolygon(new_geom)\n",
    "\n",
    "##now we can state our processing code\n",
    "path = os.path.join('..', 'data', 'countries.csv')\n",
    "countries = pandas.read_csv(path, encoding='latin-1')\n",
    "\n",
    "for idx, country_row in countries.iterrows():\n",
    "    \n",
    "    if not country_row['iso3'] in ['CAN', 'GBR']:\n",
    "        continue\n",
    "    \n",
    "    iso3 = country_row['iso3']\n",
    "    gid_region = country_row['gid_region']\n",
    "    gid_level = 'GID_{}'.format(gid_region)\n",
    "\n",
    "    filename = \"gadm36_{}.shp\".format(gid_region)\n",
    "    folder = os.path.join(\"..\", \"data\", \"raw\", \"gadm36_levels_shp\")\n",
    "    path_in = os.path.join(folder, filename)\n",
    "\n",
    "    boundaries = geopandas.read_file(path_in, crs=\"epsg:4326\")\n",
    "\n",
    "    regions = boundaries[boundaries['GID_0'] == iso3]\n",
    "\n",
    "    regions[\"geometry\"] = regions.geometry.simplify(\n",
    "        tolerance=0.01, preserve_topology=True)\n",
    "        \n",
    "    regions['geometry'] = regions.apply(\n",
    "        remove_small_shapes, axis=1)\n",
    "\n",
    "    filename = \"regional_shapes_GID_{}.shp\".format(country_row['gid_region'])\n",
    "    folder = os.path.join(\"..\", \"data\", \"processed\", country_row['iso3'], \"regions\")\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    path_out = os.path.join(folder, filename)\n",
    "    \n",
    "    regions.to_file(path_out, crs='epsg:4326')\n",
    "    \n",
    "    print(\"Processed regional boundaries for {}\".format(country_row['iso3']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d0beb1",
   "metadata": {},
   "source": [
    "Now we can create our global composite shapefile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ed0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "import os\n",
    "import pandas \n",
    "import geopandas as gpd\n",
    "\n",
    "path = os.path.join('..', 'data', 'countries.csv')\n",
    "countries = pandas.read_csv(path, encoding='latin-1')\n",
    "\n",
    "output = []\n",
    "\n",
    "for idx, country in countries.iterrows():\n",
    "\n",
    "    if not country['iso3'] in ['CAN', 'GBR']: # let's work on a single country at a time\n",
    "        continue   \n",
    "\n",
    "    print('Working on {}'.format(country['iso3']))\n",
    "    \n",
    "    #define our country-specific parameters, including gid information\n",
    "    iso3 = country['iso3']\n",
    "    gid_region = country['gid_region']\n",
    "    gid_level = 'GID_{}'.format(gid_region)\n",
    "    \n",
    "    #set the filename depending our preferred regional level\n",
    "    filename = \"regional_shapes_GID_{}.shp\".format(gid_region)\n",
    "    folder = os.path.join('..', 'data', 'processed', iso3, 'regions')\n",
    "    \n",
    "    #then load in our regions as a geodataframe\n",
    "    path_regions = os.path.join(folder, filename)\n",
    "    regions = gpd.read_file(path_regions, crs='epsg:4326')#[:2]\n",
    "\n",
    "    regions['gid_id'] = regions[gid_level]\n",
    "    regions = regions[['geometry', 'gid_id']]\n",
    "    \n",
    "    for idx, region in regions.iterrows():\n",
    "        output.append({\n",
    "            'geometry': region['geometry'],\n",
    "            'properties': {\n",
    "                'gid_id': region['gid_id']\n",
    "            }\n",
    "        })\n",
    "\n",
    "output = gpd.GeoDataFrame.from_features(output, crs='epsg:4326') \n",
    "\n",
    "filename = 'global_boundaries_composite.shp'\n",
    "path_out = os.path.join('..', 'data', 'processed', filename)\n",
    "output.to_file(path_out, crs='epsg:4326')\n",
    "\n",
    "print('Processing complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761acf7",
   "metadata": {},
   "source": [
    "## Collecting all data\n",
    "\n",
    "We can collect all data from our country folders using a loop.\n",
    "\n",
    "First we can generate a dummy example, with a .csv created for two countries. You will have your own data to collect which relates to your own research topic (therefore, you will need to adapt this code).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f3c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas \n",
    "\n",
    "path = os.path.join('..', 'data', 'countries.csv')\n",
    "countries = pandas.read_csv(path, encoding='latin-1')\n",
    "\n",
    "for idx, country in countries.iterrows():\n",
    "\n",
    "    if not country['iso3'] in ['CAN', 'GBR']:\n",
    "        continue   \n",
    "\n",
    "    print('Working on {}'.format(country['iso3']))\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    #define our country-specific parameters, including gid information\n",
    "    iso3 = country['iso3']\n",
    "    gid_region = country['gid_region']\n",
    "    gid_level = 'GID_{}'.format(gid_region)\n",
    "    \n",
    "    #set the filename depending our preferred regional level\n",
    "    #here we import the shapes as a dummy example\n",
    "    filename = \"regional_shapes_GID_{}.shp\".format(gid_region)\n",
    "    folder = os.path.join('..', 'data', 'processed', iso3, 'regions')\n",
    "    path_regions = os.path.join(folder, filename)\n",
    "    regions = gpd.read_file(path_regions, crs='epsg:4326')#[:2]\n",
    "    regions['gid_id'] = regions[gid_level]\n",
    "    regions = regions[['geometry', 'gid_id']]\n",
    "    \n",
    "    for idx, region in regions.iterrows():\n",
    "        output.append({\n",
    "            'gid_id': region['gid_id'],\n",
    "            'population': idx\n",
    "        })\n",
    "\n",
    "    #convert from list of dicts to pandas df\n",
    "    output = pandas.DataFrame(output) \n",
    "\n",
    "    filename = 'population.csv'\n",
    "    path_out = os.path.join('..', 'data', 'processed', iso3, filename)\n",
    "    output.to_csv(path_out, index=False)\n",
    "\n",
    "    print('Processing complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416bfe8",
   "metadata": {},
   "source": [
    "Now we can collect this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas \n",
    "\n",
    "path = os.path.join('..', 'data', 'countries.csv')\n",
    "countries = pandas.read_csv(path, encoding='latin-1')\n",
    "\n",
    "output = []\n",
    "\n",
    "for idx, country in countries.iterrows():\n",
    "\n",
    "    if not country['iso3'] in ['CAN', 'GBR']: # let's work on a single country at a time\n",
    "        continue   \n",
    "\n",
    "    print('Working on {}'.format(country['iso3']))\n",
    "    \n",
    "    #define our country-specific parameters, including gid information\n",
    "    iso3 = country['iso3']\n",
    "    gid_region = country['gid_region']\n",
    "    gid_level = 'GID_{}'.format(gid_region)\n",
    "    \n",
    "    #set the filename depending our preferred regional level\n",
    "    filename = \"population.csv\"\n",
    "    folder = os.path.join('..', 'data', 'processed', iso3)\n",
    "    \n",
    "    #then load in our regions as a geodataframe\n",
    "    path_population = os.path.join(folder, filename)\n",
    "    population = pandas.read_csv(path_population)#[:2]\n",
    "    \n",
    "    population = population.to_dict('records')\n",
    "    output = output + population\n",
    "    \n",
    "output = pandas.DataFrame(output) \n",
    "\n",
    "filename = 'global_population_data.csv'\n",
    "path_out = os.path.join('..', 'data', 'processed', filename)\n",
    "output.to_csv(path_out, index=False)\n",
    "\n",
    "print('Processing complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d3ec9",
   "metadata": {},
   "source": [
    "## Global map\n",
    "\n",
    "To create a global map, we only have to import our boundary composite and global data, and then merge prior to plotting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c13c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import our boundaries data\n",
    "filename = 'global_boundaries_composite.shp'\n",
    "path_in = os.path.join('..', 'data', 'processed', filename) \n",
    "boundaries = geopandas.read_file(path_in)\n",
    "\n",
    "#import our dummy population data\n",
    "filename = 'global_population_data.csv'\n",
    "path_in = os.path.join('..', 'data', 'processed', filename) \n",
    "data = pandas.read_csv(path_in)\n",
    "\n",
    "#merge our dummy population data onto our boundaries \n",
    "boundaries = boundaries.merge(data, left_on='gid_id', right_on='gid_id')\n",
    "\n",
    "#define dummy value bins and then labels for each one\n",
    "bins = [-1e6, 20, 40, 60, 80, 1e12]\n",
    "labels = ['<20','20-40','40-60','60-80','>80']\n",
    "\n",
    "#create a new variable with our dummy bin labels\n",
    "boundaries['bin'] = pandas.cut(\n",
    "    boundaries['population'],\n",
    "    bins=bins,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "#open a new seaborn figure\n",
    "sns.set(font_scale=0.9)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4.5, 4.5))\n",
    "\n",
    "#now plot our data using pandas plot\n",
    "base = boundaries.plot(column='bin', ax=ax, cmap='viridis', linewidth=0, #inferno_r\n",
    "    legend=True, antialiased=False)\n",
    "\n",
    "#allocate a plot title \n",
    "n = len(boundaries)\n",
    "name = 'Dummy Population by Sub-Region Globally (n={})'.format(n)\n",
    "fig.suptitle(name)\n",
    "\n",
    "#specify where to write our .png file to\n",
    "path = os.path.join('..', 'data', 'processed', 'fig.png')\n",
    "fig.savefig(path)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ab92c",
   "metadata": {},
   "source": [
    "Congratulations, you should now be very close to completing the global assessment coursework!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
